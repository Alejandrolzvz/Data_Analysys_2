{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/predict-customer-churn-in-python-e8cd6d3aaa7\n",
    "\n",
    "#Step 0: Restarting the session and Clearning all temporary variables----------------------------\n",
    "\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    get_ipython().magic('clear')\n",
    "    get_ipython().magic('reset -f')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section A: Data Preprocessing------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Import relevant libraries---------------------------------------------------------\n",
    "\n",
    "#Standard libraries for data analysis:----------------------\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# sklearn modules for data preprocessing-------------------------------------\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "#sklearn modules for Model Selection--------------------------------------\n",
    "\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#sklearn modules for Model Evaluation & Improvement---------------------------\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "  \n",
    "\n",
    "#Standard libraries for data visualization---------------------\n",
    "\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "color = sn.color_palette()\n",
    "import matplotlib.ticker as mtick\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "#Miscellaneous Utilitiy Libraries--------------------------------------\n",
    "    \n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import timeit\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from dateutil.parser import parse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Set up current working directory------------------------------------------\n",
    "\n",
    "# os.chdir(r\"C:/Users/srees/Desktop/Blogs and Projects/Upcoming Blogs and Projects/2. Propensity Scoring Models/3. Predict Customer Churn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Import the dataset--------------------------------------------------------\n",
    "\n",
    "dataset = pd.read_csv('churning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate Datastructure --------------------------------------------------------\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recheck Column Datatypes and Missing Values:\n",
    "    \n",
    "dataset.columns.to_series().groupby(dataset.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique values in each categorical variable:\n",
    "\n",
    "dataset[\"PaymentMethod\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"PaymentMethod\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Contract\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Contract\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Check Target Variable Distribution ----------------------------------------------- \n",
    "\n",
    "dataset[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================\n",
    "#In this case, we have class imbalance with few negatives. In our business challenge, \n",
    "#false negatives are costly. Hence let's keep an eye onto the Precision, Recall & F2 score besides accuracy\n",
    "# ======================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Clean the Dataset----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'],errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TotalCharges'] = dataset['TotalCharges'].astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Take care of missing data---------------------------------------------------------------\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*Find the average and fill missing values of each columns programmatically.\n",
    "\n",
    "na_cols = dataset.isna().any()\n",
    "\n",
    "na_cols = na_cols[na_cols == True].reset_index()\n",
    "\n",
    "na_cols = na_cols[\"index\"].tolist()\n",
    "\n",
    "for col in dataset.columns[1:]:\n",
    "     if col in na_cols:\n",
    "        if dataset[col].dtype != 'object':\n",
    "             dataset[col] =  dataset[col].fillna(dataset[col].mean()).round(0)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revalidate:\n",
    "  \n",
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8: label Encode Binary data----------------------------------------------------------------\n",
    "\n",
    "#Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Label Encoding will be used for columns with 2 or less unique values\n",
    "le_count = 0\n",
    "for col in dataset.columns[1:]:\n",
    "    if dataset[col].dtype == 'object':\n",
    "        if len(list(dataset[col].unique())) <= 2:\n",
    "            le.fit(dataset[col])\n",
    "            dataset[col] = le.transform(dataset[col])\n",
    "            le_count += 1\n",
    "print('{} columns were label encoded.'.format(le_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section B: Data Evaluation------------------------------------------\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "#Step 9: Exploratory Data Analysis----------------------------------------------------------------------\n",
    "  \n",
    "#Step 9.1. Plot Histogram of numeric Columns--------------------------------------\n",
    "\n",
    "dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling',\n",
    "        'MonthlyCharges', 'TotalCharges']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram:\n",
    "    \n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.suptitle('Histograms of Numerical Columns\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = 24, fontfamily = \"sans-serif\")\n",
    "for i in range(dataset2.shape[1]):\n",
    "    plt.subplot(6, 3, i + 1)\n",
    "    f = plt.gca()\n",
    "    f.set_title(dataset2.columns.values[i])\n",
    "\n",
    "    vals = np.size(dataset2.iloc[:, i].unique())\n",
    "    if vals >= 100:\n",
    "        vals = 100\n",
    "    \n",
    "    plt.hist(dataset2.iloc[:, i], bins=vals, color = '#ec838a')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9.2. Analyze distribution of Key Categorical Variables---------------------------------------------\n",
    " \n",
    "    \n",
    "#(1) Distribution of Contract Type----------------------------------------------------------------------------------------\n",
    "\n",
    "contract_split = dataset[[ \"customerID\", \"Contract\"]]\n",
    "sectors = contract_split .groupby (\"Contract\")\n",
    "contract_split = pd.DataFrame(sectors[\"customerID\"].count())\n",
    "contract_split.rename(columns={'customerID':'No. of customers'}, inplace=True)\n",
    "\n",
    "\n",
    "ax =  contract_split[[\"No. of customers\"]].plot.bar(title = 'Customers by Contract Type', legend =True, table = False, grid = False,  subplots = False,  figsize =(12, 7), color ='#ec838a', fontsize = 15, stacked=False)\n",
    "\n",
    "plt.ylabel('No. of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('\\n Contract Type',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Customers by Contract Type \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "x_labels = np.array(contract_split[[\"No. of customers\"]])\n",
    "\n",
    "def add_value_labels(ax, spacing=5):   \n",
    "    for rect in ax.patches:      \n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2       \n",
    "        space = spacing        \n",
    "        va = 'bottom'      \n",
    "        if y_value < 0:           \n",
    "            space *= -1            \n",
    "            va = 'top'       \n",
    "        label = \"{:.0f}\".format(y_value)      \n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),         \n",
    "            xytext=(0, space),          \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)                                                             \n",
    "add_value_labels(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) Distribution of Payment Method Type---------------------------------------------------------------------------------------\n",
    "\n",
    "payment_method_split = dataset[[ \"customerID\", \"PaymentMethod\"]]\n",
    "sectors = payment_method_split  .groupby (\"PaymentMethod\")\n",
    "payment_method_split  = pd.DataFrame(sectors[\"customerID\"].count())\n",
    "payment_method_split.rename(columns={'customerID':'No. of customers'}, inplace=True)\n",
    "\n",
    "\n",
    "ax =  payment_method_split [[\"No. of customers\"]].plot.bar(title = 'Customers by Payment Method', legend =True, table = False, grid = False,  subplots = False,  figsize =(15, 10), color ='#ec838a', fontsize = 15, stacked=False)\n",
    "\n",
    "plt.ylabel('No. of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('\\n Contract Type',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Customers by Payment Method \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "x_labels = np.array(payment_method_split [[\"No. of customers\"]])\n",
    "\n",
    "def add_value_labels(ax, spacing=5):   \n",
    "    for rect in ax.patches:      \n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2       \n",
    "        space = spacing        \n",
    "        va = 'bottom'      \n",
    "        if y_value < 0:           \n",
    "            space *= -1            \n",
    "            va = 'top'       \n",
    "        label = \"{:.0f}\".format(y_value)      \n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),         \n",
    "            xytext=(0, space),          \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)                                                             \n",
    "add_value_labels(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) Distribution of various Label Encoded Categorical Variables---------------------------------------------------------------------------------------\n",
    "\n",
    "services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',\n",
    "           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 3,ncols = 3,figsize = (15,12))\n",
    "for i, item in enumerate(services):\n",
    "    if i < 3:\n",
    "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i,0],rot = 0, color ='#f3babc' )\n",
    "        \n",
    "    elif i >=3 and i < 6:\n",
    "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i-3,1],rot = 0,color ='#9b9c9a')\n",
    "        \n",
    "    elif i < 9:\n",
    "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i-6,2],rot = 0,color = '#ec838a')\n",
    "    ax.set_title(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9.3: Analyze Churn Rate by Categorical variables:   -------------------------------------------------------------\n",
    "\n",
    "#(1) Overall Churn Rate------------------------------------------------------------------------------------------\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "churn_rate = dataset[[\"Churn\", \"customerID\"]]\n",
    "churn_rate [\"churn_label\"] = pd.Series(np.where((churn_rate[\"Churn\"] == 0), \"No\", \"Yes\"))\n",
    "sectors = churn_rate .groupby (\"churn_label\")\n",
    "churn_rate = pd.DataFrame(sectors[\"customerID\"].count())\n",
    "churn_rate [\"Churn Rate\"] = (churn_rate [\"customerID\"] / sum(churn_rate [\"customerID\"]) )*100\n",
    "ax =  churn_rate[[\"Churn Rate\"]].plot.bar(title = 'Overall Churn Rate', legend =True, table = False, grid = False,  subplots = False,  figsize =(12, 7), color = '#ec838a', fontsize = 15, stacked=False, ylim =(0,100))\n",
    "\n",
    "plt.ylabel('Proportion of Customers',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Churn',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Overall Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "x_labels = np.array(churn_rate[[\"customerID\"]])\n",
    "\n",
    "def add_value_labels(ax, spacing=5):   \n",
    "    for rect in ax.patches:     \n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2       \n",
    "        space = spacing\n",
    "        va = 'bottom'        \n",
    "        if y_value < 0:           \n",
    "            space *= -1          \n",
    "            va = 'top'\n",
    "        \n",
    "        label = \"{:.1f}%\".format(y_value)    \n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),        \n",
    "            xytext=(0, space),         \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)                                                            \n",
    "add_value_labels(ax)\n",
    "ax.autoscale(enable=False, axis='both', tight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(2) Churn Rate by Contract Type ----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "contract_churn = dataset.groupby(['Contract','Churn']).size().unstack()\n",
    "\n",
    "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "colors  = ['#ec838a','#9b9c9a']\n",
    "\n",
    "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                width = 0.3,\n",
    "                                                                stacked = True,\n",
    "                                                                rot = 0, \n",
    "                                                                figsize = (12,7),\n",
    "                                                                color = colors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Contract Type\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Churn Rate by Contract type \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x+width/2, \n",
    "            y+height/2, \n",
    "            '{:.1f}%'.format(height), \n",
    "            horizontalalignment='center', \n",
    "            verticalalignment='center')\n",
    "ax.autoscale(enable=False, axis='both', tight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3) Churn Rate by Payment Method Type----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "contract_churn = dataset.groupby(['Contract','PaymentMethod']).size().unstack()\n",
    "\n",
    "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "colors  = ['#ec838a','#9b9c9a', '#f3babc' , '#4d4f4c']\n",
    "\n",
    "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                width = 0.3,\n",
    "                                                                stacked = True,\n",
    "                                                                rot = 0, \n",
    "                                                                figsize = (12,7),\n",
    "                                                                color = colors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Contract Type\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Churn Rate by Payment Method \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x+width/2, \n",
    "            y+height/2, \n",
    "            '{:.1f}%'.format(height), \n",
    "            horizontalalignment='center', \n",
    "            verticalalignment='center')\n",
    "ax.autoscale(enable=False, axis='both', tight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9.4. Find positive and negative correlations with the Response Variable--------------------\n",
    "\n",
    "dataset2 = dataset[['SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling',\n",
    "        'MonthlyCharges', 'TotalCharges']]\n",
    "\n",
    "correlations = dataset2.corrwith(dataset.Churn)\n",
    "correlations = correlations[correlations!=1]\n",
    "positive_correlations = correlations[correlations >0].sort_values(ascending = False)\n",
    "negative_correlations = correlations[correlations<0].sort_values(ascending = False)\n",
    "\n",
    "print('Most Positive Correlations: \\n', positive_correlations)\n",
    "print('\\nMost Negative Correlations: \\n', negative_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10.4. Plot positive & negative correlation with Response Variable-----------------------------\n",
    "\n",
    "correlations = dataset2.corrwith(dataset.Churn)\n",
    "correlations = correlations[correlations!=1]\n",
    "\n",
    "correlations.plot.bar(\n",
    "        figsize = (18, 10), fontsize = 15, color = '#ec838a',\n",
    "        rot = 45, grid = True)\n",
    "\n",
    "plt.title('Correlation with Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9.5. Plot Correlation Matrix of all independent variables------------------------\n",
    "\n",
    "## Set and compute the Correlation Matrix\n",
    "sn.set(style=\"white\")\n",
    "corr = dataset2.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure and a diverging colormap\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "cmap = sn.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9.6: Check Multicolinearity using VIF----------------------------------------------\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges','TotalCharges']]\n",
    "\n",
    "calc_vif(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Charges seem to be colinear with Monthly Charges.\n",
    "\n",
    "#check colinearity:\n",
    "    \n",
    "dataset2[['MonthlyCharges', 'TotalCharges']].plot.scatter(figsize = (15, 10), x = 'MonthlyCharges',\n",
    "                                                              y='TotalCharges', color =  '#ec838a')\n",
    "\n",
    "\n",
    "plt.title('Co-linearity of Monthly Charges and Total Charges \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping TotalCharges:\n",
    "    \n",
    "dataset2 = dataset2.drop(columns = \"TotalCharges\")\n",
    "\n",
    "#Revalidate Colinearity:\n",
    "\n",
    "dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges']]\n",
    "\n",
    "calc_vif(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying changes in the main dataset:\n",
    "    \n",
    "dataset = dataset.drop(columns = \"TotalCharges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 10: Encode Categorical data----------------------------------------------------------------\n",
    "\n",
    "#Incase if user_id is an object:\n",
    "    \n",
    "identity = dataset[\"customerID\"]\n",
    "\n",
    "dataset = dataset.drop(columns=\"customerID\")\n",
    "\n",
    "# convert rest of categorical variable into dummy\n",
    "\n",
    "dataset= pd.get_dummies(dataset)\n",
    "\n",
    "#Rejoin userid to dataset (column concatenation)\n",
    "\n",
    "dataset = pd.concat([dataset, identity], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 11: Split dataset into dependent and independent variables-----------------------------------\n",
    "\n",
    "#identify response variable:\n",
    "    \n",
    "response = dataset[\"Churn\"]\n",
    "\n",
    "dataset = dataset.drop(columns=\"Churn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 12: Generate training and test datasets of dependent and independent variables-----------------\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, response,\n",
    "                                                    stratify=response, \n",
    "                                                    test_size = 0.2, #use 0.9 if data is huge.\n",
    "                                                    random_state = 0)\n",
    "\n",
    "#to resolve any class imbalance - use stratify parameter.\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Removing Identifiers-------------------------------------------------------------------\n",
    "\n",
    "train_identity = X_train['customerID']\n",
    "X_train = X_train.drop(columns = ['customerID'])\n",
    "\n",
    "test_identity = X_test['customerID']\n",
    "X_test = X_test.drop(columns = ['customerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Feature Scaling-----------------------------------------------------------------------\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_train = X_train2\n",
    "\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section C: Model Selection------------------------------------------\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 15.1: Compare Baseline Classification Algorithms - First Iteration\n",
    "#Using Accuracy and ROC AUC Mean Metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0,\n",
    "                                                         class_weight='balanced')))\n",
    "\n",
    "models.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\n",
    "\n",
    "\n",
    "models.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\n",
    "\n",
    "\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\n",
    "\n",
    "\n",
    "models.append(('Gaussian NB', GaussianNB()))\n",
    "\n",
    "\n",
    "models.append(('Decision Tree Classifier',\n",
    "               DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\n",
    "\n",
    "\n",
    "models.append(('Random Forest', RandomForestClassifier(\n",
    "    n_estimators=100, criterion = 'entropy', random_state = 0)))\n",
    "\n",
    "#Evaluating Model Results: \n",
    "\n",
    "    \n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "# set table to table to populate with performance results\n",
    "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n",
    "       'Accuracy Mean', 'Accuracy STD']\n",
    "\n",
    "model_results = pd.DataFrame(columns=col)\n",
    "i = 0\n",
    "# evaluate each model using k-fold cross-validation\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(\n",
    "        n_splits=10, random_state=0)  # 10-fold cross-validation\n",
    "\n",
    "    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "    \n",
    "model_results.sort_values(by=['ROC AUC Mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 15.2.  Visualize Classification Algorithms Accuracy Comparisons:-----------------------------------\n",
    "\n",
    "  \n",
    "#Using Accuracy Mean:\n",
    "    \n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(acc_results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "\n",
    "\n",
    "#plt.ylabel('ROC AUC Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "#plt.xlabel('\\n Baseline Classification Algorithms\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Accuracy Score Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#using Area under ROC Curve:\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(auc_results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "\n",
    "#plt.ylabel('ROC AUC Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "#plt.xlabel('\\n Baseline Classification Algorithms\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('ROC AUC Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "#Compare Baseline Classification Algorithms - Second Iteration\n",
    "#Using Accuracy, Precision, Recall, F1 and F2 Score Metrics\n",
    "#-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 15.3. Get the right parameters for the baseline models:---------------------------\n",
    "\n",
    "#Identify optimal number of K neighbors for KNN Model:\n",
    "\n",
    "\n",
    "score_array = []\n",
    "for each in range(1,25):\n",
    "    knn_loop = KNeighborsClassifier(n_neighbors = each) #set K neighbor as 3\n",
    "    knn_loop.fit(X_train,y_train)\n",
    "    score_array.append(knn_loop.score(X_test,y_test))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1,25),score_array, color = '#ec838a')\n",
    "\n",
    "\n",
    "plt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Optimal Number of K Neighbors \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#optimal number of K neigbors = 22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify optimal number of trees for Random Forest Model:\n",
    " \n",
    "score_array = []\n",
    "for each in range(1,100):\n",
    "    rf_loop = RandomForestClassifier(n_estimators = each, random_state = 1) \n",
    "    rf_loop.fit(X_train,y_train)\n",
    "    score_array.append(rf_loop.score(X_test,y_test))\n",
    " \n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1,100),score_array, color = '#ec838a')\n",
    "\n",
    "\n",
    "plt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Optimal Number of Trees for Random Forest Model \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    " \n",
    " \n",
    "#Optimal number of decision trees = 72\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 15.4. Compare Baseline Classification Algorithms - Second Iteration-----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Step 15.4.1. Logistic Regression-----------------\n",
    "\n",
    "# Fitting Logistic Regression to the Training set \n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "\n",
    "\n",
    "#Step 15.4.2. . Support Vector Machine (linear classifier)------------------------\n",
    "\n",
    "\n",
    "# Fitting SVM (SVC class) to the Training set:\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "\n",
    "#Step 15.4.3. K-Nearest Neighbours------------------------\n",
    "\n",
    "\n",
    "# Fitting KNN to the Training set:\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 22, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred  = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['K-Nearest Neighbours', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "#Step 15.4.4.  Kernel SVM------------------------\n",
    "\n",
    "# Fitting Kernel SVM to the Training set:\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Kernel SVM', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "\n",
    "#Step 15.4.5.  Naive Byes------------------------------------------------\n",
    "\n",
    "# Fitting Naive Byes to the Training set:\n",
    "    \n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Naive Byes', acc, prec, rec, f1, f2]],\n",
    "                columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "#Step 15.4.6. Decision Tree---------------------------------------------\n",
    "\n",
    "\n",
    "# Fitting Decision Tree to the Training set:\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "\n",
    "#Step 15.4.7. Random Forest--------------------------------------------\n",
    "\n",
    "\n",
    "# Fitting Random Forest to the Training set:\n",
    "    \n",
    "classifier = RandomForestClassifier(n_estimators = 72, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 15.5. Visualize the results and compare the baseline algorithms----------------------------------\n",
    "\n",
    "# =======================================================================================================================\n",
    "#Sort results based on the right classification metric:\n",
    "#(Accuracy/ROC_AUC / Precision/Recall/F1/F2 scores)\n",
    "\n",
    "#Since we have class imbalance. When we look into the business challenge, \n",
    "# our false negatives will be costly and hence we need to Keep an eye onto the Precision, Recall & F2 score besides accuracy\n",
    "# =======================================================================================================================\n",
    "\n",
    "results = results.sort_values([\"Precision\", \"Recall\", \"F2 Score\"], ascending = False)\n",
    "    \n",
    "\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section D: Model Evaluation (Logistic Regression)----------------------\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 16: Train & evaluate Chosen Model---------------------------------------------\n",
    "    \n",
    "    \n",
    "# Fit Logistic Regression on the Training dataset:\n",
    "    \n",
    "classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict the Test set results\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "#Evaluate Model Results on Test Set:\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "print (results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-check k-Fold Cross Validation:\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Logistic Regression Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize results on a Confusion Matrix:\n",
    "    \n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (28,20))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g'#,cmap=\"YlGnBu\" \n",
    "           )\n",
    "class_names=[0,1]\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix\\n', y=1.1)\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.ylabel('Actual label\\n')\n",
    "plt.xlabel('Predicted label\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using ROC Graph\n",
    "\n",
    "classifier.fit(X_train, y_train) \n",
    "probs = classifier.predict_proba(X_test) \n",
    "probs = probs[:, 1] \n",
    "classifier_roc_auc = accuracy_score(y_test, y_pred )\n",
    "\n",
    "\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Logistic Regression ROC\n",
    "plt.plot(rf_fpr, rf_tpr, label='Logistic Regression (area = %0.2f)' % classifier_roc_auc)\n",
    "# Plot Base Rate ROC\n",
    "plt.plot([0,1], [0,1],label='Base Rate' 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('True Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('\\nFalse Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
    "plt.title('ROC Graph \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc=\"lower right\", fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 17:Predict Feature Importance------------------------------------------------------\n",
    " \n",
    "\n",
    "# Analyzing Coefficients\n",
    "feature_importances = pd.concat([pd.DataFrame(dataset.drop(columns = 'customerID').columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n",
    "\n",
    "feature_importances.sort_values(\"coef\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section E: Model Improvement (Logistic Regression)----------------------------\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 18:Hyper parameter Tuning  --------------------------------------\n",
    "\n",
    "\n",
    "# Round 1: -----------------------------------------------------------------\n",
    " \n",
    "# Select Regularization Method   \n",
    "import time\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Combine Parameters\n",
    "parameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "lr_classifier = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"balanced_accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "t0 = time.time()\n",
    "lr_classifier  = lr_classifier .fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "lr_best_accuracy = lr_classifier.best_score_\n",
    "lr_best_parameters = lr_classifier.best_params_\n",
    "lr_best_accuracy, lr_best_parameters\n",
    "\n",
    "#verdict: No accuracy lift post hyperparameter tuning (round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 2: -----------------------------------------------------------------\n",
    "    \n",
    "\n",
    "# Select Regularization Method\n",
    "import time\n",
    "penalty = ['l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = [ 0.0001, 0.001, 0.01, 0.02, 0.05]\n",
    "\n",
    "# Combine Parameters\n",
    "parameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "lr_classifier = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = \"balanced_accuracy\",\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "t0 = time.time()\n",
    "lr_classifier  = lr_classifier .fit(X_train, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Took %0.2f seconds\" % (t1 - t0))\n",
    "\n",
    "lr_best_accuracy = lr_classifier.best_score_\n",
    "lr_best_parameters = lr_classifier.best_params_\n",
    "lr_best_accuracy, lr_best_parameters\n",
    "\n",
    "#verdict: No accuracy lift post hyperparameter tuning (round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 18.3:Final Hyper parameter tuning and selection --------------------------------------\n",
    "\n",
    "\n",
    "lr_classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict the Test set results\n",
    "\n",
    "y_pred = lr_classifier.predict(X_test)\n",
    "\n",
    "#probability score\n",
    "y_pred_probs = lr_classifier.predict_proba(X_test)\n",
    "y_pred_probs  = y_pred_probs [:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section F: Comparing Model Predictions against test set----------------\n",
    "#----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 19: Compare predictions against test set -------------------------------------------------------\n",
    "\n",
    "\n",
    "#Revalidate final results with Confusion Matrix:\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "print (cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix as a quick Crosstab:\n",
    "    \n",
    "pd.crosstab(y_test,pd.Series(y_pred),rownames=['ACTUAL'],colnames=['PRED'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize Confusion Matrix:\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (28,20))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g'#,cmap=\"YlGnBu\" \n",
    "           )\n",
    "class_names=[0,1]\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix\\n', y=1.1)\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.ylabel('Actual label\\n')\n",
    "plt.xlabel('Predicted label\\n')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 20: Format Final Results:-------------------------------------------------------\n",
    "\n",
    "\n",
    "final_results = pd.concat([test_identity, y_test], axis = 1).dropna()\n",
    "\n",
    "final_results['predictions'] = y_pred \n",
    "\n",
    "final_results[\"propensity_to_convert(%)\"] = y_pred_probs \n",
    "\n",
    "final_results[\"propensity_to_convert(%)\"] = final_results[\"propensity_to_convert(%)\"]*100\n",
    "\n",
    "final_results[\"propensity_to_convert(%)\"]=final_results[\"propensity_to_convert(%)\"].round(2)\n",
    "\n",
    "final_results = final_results[['customerID', 'Churn', 'predictions', 'propensity_to_convert(%)']]\n",
    "\n",
    "final_results ['Ranking'] = pd.qcut(final_results['propensity_to_convert(%)'].rank(method = 'first'),10,labels=range(10,0,-1))\n",
    "\n",
    "print (final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------\n",
    "#-----------------Section G: Deploy the Model and Predict Future Datapoints---------------\n",
    "#----------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 21: Save the model-------------------------------------------------------------------\n",
    "\n",
    "filename = 'final_model.model'\n",
    "i = [lr_classifier]\n",
    "joblib.dump(i,filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
